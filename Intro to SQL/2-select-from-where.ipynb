{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d16dac0",
   "metadata": {
    "papermill": {
     "duration": 0.018048,
     "end_time": "2021-11-09T00:03:59.484998",
     "exception": false,
     "start_time": "2021-11-09T00:03:59.466950",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Now that you know how to access and examine a dataset, you're ready to write your first SQL query!  As you'll soon see, SQL queries will help you sort through a massive dataset, to retrieve only the information that you need.  \n",
    "\n",
    "We'll begin by using the keywords **SELECT**, **FROM**, and **WHERE** to get data from specific columns based on conditions you specify. \n",
    "\n",
    "For clarity, we'll work with a small imaginary dataset `pet_records` which contains just one table, called `pets`. \n",
    "\n",
    "![](https://i.imgur.com/fI5Pvvp.png)\n",
    "\n",
    "# SELECT ... FROM\n",
    "\n",
    "The most basic SQL query selects a single column from a single table.  To do this, \n",
    "- specify the column you want after the word **SELECT**, and then \n",
    "- specify the table after the word **FROM**.  \n",
    "\n",
    "For instance, to select the `Name` column (from the `pets` table in the `pet_records` database in the `bigquery-public-data` project), our query would appear as follows:  \n",
    "\n",
    "![](https://i.imgur.com/c3GxYRt.png)\n",
    "\n",
    "Note that when writing an SQL query, the argument we pass to **FROM** is *not* in single or double quotation marks (' or \"). It is in backticks (\\`).\n",
    "\n",
    "# WHERE ...\n",
    "\n",
    "BigQuery datasets are large, so you'll usually want to return only the rows meeting specific conditions. You can do this using the **WHERE** clause.\n",
    "\n",
    "The query below returns the entries from the `Name` column that are in rows where the `Animal` column has the text `'Cat'`. \n",
    "\n",
    "![](https://i.imgur.com/HJOT8Kb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa96ac5",
   "metadata": {
    "papermill": {
     "duration": 0.015991,
     "end_time": "2021-11-09T00:03:59.517989",
     "exception": false,
     "start_time": "2021-11-09T00:03:59.501998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Example: What are all the U.S. cities in the OpenAQ dataset?\n",
    "\n",
    "Now that you've got the basics down, let's work through an example with a real dataset. We'll use an [OpenAQ](https://openaq.org) dataset about air quality.\n",
    "\n",
    "First, we'll set up everything we need to run queries and take a quick peek at what tables are in our database.  (_Since you learned how to do this in the previous tutorial, we have hidden the code.  But if you'd like to take a peek, you need only click on the \"Code\" button below._)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc13084",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-11-09T00:03:59.557551Z",
     "iopub.status.busy": "2021-11-09T00:03:59.556327Z",
     "iopub.status.idle": "2021-11-09T00:04:00.299174Z",
     "shell.execute_reply": "2021-11-09T00:04:00.298514Z"
    },
    "papermill": {
     "duration": 0.762942,
     "end_time": "2021-11-09T00:04:00.299358",
     "exception": false,
     "start_time": "2021-11-09T00:03:59.536416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_air_quality\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"openaq\" dataset\n",
    "dataset_ref = client.dataset(\"openaq\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# List all the tables in the \"openaq\" dataset\n",
    "tables = list(client.list_tables(dataset))\n",
    "\n",
    "# Print names of all tables in the dataset (there's only one!)\n",
    "for table in tables:  \n",
    "    print(table.table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2449266",
   "metadata": {
    "papermill": {
     "duration": 0.016882,
     "end_time": "2021-11-09T00:04:00.333855",
     "exception": false,
     "start_time": "2021-11-09T00:04:00.316973",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The dataset contains only one table, called `global_air_quality`.  We'll fetch the table and take a peek at the first few rows to see what sort of data it contains.  (_Again, we have hidden the code.  To take a peek, click on the \"Code\" button below._)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e0f919",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-11-09T00:04:00.374612Z",
     "iopub.status.busy": "2021-11-09T00:04:00.373899Z",
     "iopub.status.idle": "2021-11-09T00:04:01.001996Z",
     "shell.execute_reply": "2021-11-09T00:04:01.002581Z"
    },
    "papermill": {
     "duration": 0.651735,
     "end_time": "2021-11-09T00:04:01.002756",
     "exception": false,
     "start_time": "2021-11-09T00:04:00.351021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>pollutant</th>\n",
       "      <th>value</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>unit</th>\n",
       "      <th>source_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>averaged_over_in_hours</th>\n",
       "      <th>location_geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Borówiec, ul. Drapałka</td>\n",
       "      <td>Borówiec</td>\n",
       "      <td>PL</td>\n",
       "      <td>bc</td>\n",
       "      <td>0.85217</td>\n",
       "      <td>2022-04-28 07:00:00+00:00</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>GIOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.276794</td>\n",
       "      <td>17.074114</td>\n",
       "      <td>POINT(52.276794 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kraków, ul. Bulwarowa</td>\n",
       "      <td>Kraków</td>\n",
       "      <td>PL</td>\n",
       "      <td>bc</td>\n",
       "      <td>0.91284</td>\n",
       "      <td>2022-04-27 23:00:00+00:00</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>GIOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.069308</td>\n",
       "      <td>20.053492</td>\n",
       "      <td>POINT(50.069308 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Płock, ul. Reja</td>\n",
       "      <td>Płock</td>\n",
       "      <td>PL</td>\n",
       "      <td>bc</td>\n",
       "      <td>1.41000</td>\n",
       "      <td>2022-03-30 04:00:00+00:00</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>GIOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.550938</td>\n",
       "      <td>19.709791</td>\n",
       "      <td>POINT(52.550938 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elbląg, ul. Bażyńskiego</td>\n",
       "      <td>Elbląg</td>\n",
       "      <td>PL</td>\n",
       "      <td>bc</td>\n",
       "      <td>0.33607</td>\n",
       "      <td>2022-05-03 13:00:00+00:00</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>GIOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.167847</td>\n",
       "      <td>19.410942</td>\n",
       "      <td>POINT(54.167847 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Piastów, ul. Pułaskiego</td>\n",
       "      <td>Piastów</td>\n",
       "      <td>PL</td>\n",
       "      <td>bc</td>\n",
       "      <td>0.51000</td>\n",
       "      <td>2022-05-11 05:00:00+00:00</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>GIOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.191728</td>\n",
       "      <td>20.837489</td>\n",
       "      <td>POINT(52.191728 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  location      city country pollutant    value  \\\n",
       "0   Borówiec, ul. Drapałka  Borówiec      PL        bc  0.85217   \n",
       "1    Kraków, ul. Bulwarowa    Kraków      PL        bc  0.91284   \n",
       "2          Płock, ul. Reja     Płock      PL        bc  1.41000   \n",
       "3  Elbląg, ul. Bażyńskiego    Elbląg      PL        bc  0.33607   \n",
       "4  Piastów, ul. Pułaskiego   Piastów      PL        bc  0.51000   \n",
       "\n",
       "                  timestamp   unit source_name  latitude  longitude  \\\n",
       "0 2022-04-28 07:00:00+00:00  µg/m³        GIOS       1.0  52.276794   \n",
       "1 2022-04-27 23:00:00+00:00  µg/m³        GIOS       1.0  50.069308   \n",
       "2 2022-03-30 04:00:00+00:00  µg/m³        GIOS       1.0  52.550938   \n",
       "3 2022-05-03 13:00:00+00:00  µg/m³        GIOS       1.0  54.167847   \n",
       "4 2022-05-11 05:00:00+00:00  µg/m³        GIOS       1.0  52.191728   \n",
       "\n",
       "   averaged_over_in_hours       location_geom  \n",
       "0               17.074114  POINT(52.276794 1)  \n",
       "1               20.053492  POINT(50.069308 1)  \n",
       "2               19.709791  POINT(52.550938 1)  \n",
       "3               19.410942  POINT(54.167847 1)  \n",
       "4               20.837489  POINT(52.191728 1)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a reference to the \"global_air_quality\" table\n",
    "table_ref = dataset_ref.table(\"global_air_quality\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"global_air_quality\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc41f7",
   "metadata": {
    "papermill": {
     "duration": 0.018952,
     "end_time": "2021-11-09T00:04:01.039924",
     "exception": false,
     "start_time": "2021-11-09T00:04:01.020972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Everything looks good! So, let's put together a query. Say we want to select all the values from the `city` column that are in rows where the `country` column is `'US'` (for \"United States\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0897266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:04:01.080924Z",
     "iopub.status.busy": "2021-11-09T00:04:01.079887Z",
     "iopub.status.idle": "2021-11-09T00:04:01.083945Z",
     "shell.execute_reply": "2021-11-09T00:04:01.084624Z"
    },
    "papermill": {
     "duration": 0.026262,
     "end_time": "2021-11-09T00:04:01.084810",
     "exception": false,
     "start_time": "2021-11-09T00:04:01.058548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query to select all the items from the \"city\" column where the \"country\" column is 'US'\n",
    "query = \"\"\"\n",
    "        SELECT city\n",
    "        FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "        WHERE country = 'US'\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe7741a",
   "metadata": {
    "papermill": {
     "duration": 0.018102,
     "end_time": "2021-11-09T00:04:01.121338",
     "exception": false,
     "start_time": "2021-11-09T00:04:01.103236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Take the time now to ensure that this query lines up with what you learned above.  \n",
    "\n",
    "# Submitting the query to the dataset\n",
    "\n",
    "We're ready to use this query to get information from the OpenAQ dataset.  As in the previous tutorial, the first step is to create a [`Client`](https://google-cloud.readthedocs.io/en/latest/bigquery/generated/google.cloud.bigquery.client.Client.html#google.cloud.bigquery.client.Client) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3b17cf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:04:01.162158Z",
     "iopub.status.busy": "2021-11-09T00:04:01.161152Z",
     "iopub.status.idle": "2021-11-09T00:04:01.167248Z",
     "shell.execute_reply": "2021-11-09T00:04:01.166611Z"
    },
    "papermill": {
     "duration": 0.027575,
     "end_time": "2021-11-09T00:04:01.167430",
     "exception": false,
     "start_time": "2021-11-09T00:04:01.139855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8c9e74",
   "metadata": {
    "papermill": {
     "duration": 0.018413,
     "end_time": "2021-11-09T00:04:01.204893",
     "exception": false,
     "start_time": "2021-11-09T00:04:01.186480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We begin by setting up the query with the [`query()`](https://google-cloud.readthedocs.io/en/latest/bigquery/generated/google.cloud.bigquery.client.Client.query.html#google.cloud.bigquery.client.Client.query) method.  We run the method with the default parameters, but this method also allows us to specify more complicated settings that you can read about in [the documentation](https://google-cloud.readthedocs.io/en/latest/bigquery/generated/google.cloud.bigquery.client.Client.query.html#google.cloud.bigquery.client.Client.query).  We'll revisit this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02059269",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:04:01.250170Z",
     "iopub.status.busy": "2021-11-09T00:04:01.249418Z",
     "iopub.status.idle": "2021-11-09T00:04:01.715296Z",
     "shell.execute_reply": "2021-11-09T00:04:01.714747Z"
    },
    "papermill": {
     "duration": 0.491779,
     "end_time": "2021-11-09T00:04:01.715471",
     "exception": false,
     "start_time": "2021-11-09T00:04:01.223692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the query\n",
    "query_job = client.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47da487c",
   "metadata": {
    "papermill": {
     "duration": 0.018782,
     "end_time": "2021-11-09T00:04:01.753547",
     "exception": false,
     "start_time": "2021-11-09T00:04:01.734765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we run the query and convert the results to a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d2a4eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:04:01.796328Z",
     "iopub.status.busy": "2021-11-09T00:04:01.795694Z",
     "iopub.status.idle": "2021-11-09T00:04:02.426261Z",
     "shell.execute_reply": "2021-11-09T00:04:02.426798Z"
    },
    "papermill": {
     "duration": 0.654395,
     "end_time": "2021-11-09T00:04:02.426997",
     "exception": false,
     "start_time": "2021-11-09T00:04:01.772602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# API request - run the query, and return a pandas DataFrame\n",
    "us_cities = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672aa800",
   "metadata": {
    "papermill": {
     "duration": 0.019802,
     "end_time": "2021-11-09T00:04:02.467247",
     "exception": false,
     "start_time": "2021-11-09T00:04:02.447445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we've got a pandas DataFrame called `us_cities`, which we can use like any other DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ff9a30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:04:02.517450Z",
     "iopub.status.busy": "2021-11-09T00:04:02.516616Z",
     "iopub.status.idle": "2021-11-09T00:04:02.519597Z",
     "shell.execute_reply": "2021-11-09T00:04:02.520072Z"
    },
    "papermill": {
     "duration": 0.033595,
     "end_time": "2021-11-09T00:04:02.520253",
     "exception": false,
     "start_time": "2021-11-09T00:04:02.486658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phoenix-Mesa-Scottsdale                     39414\n",
       "Los Angeles-Long Beach-Santa Ana            27479\n",
       "Riverside-San Bernardino-Ontario            26887\n",
       "New York-Northern New Jersey-Long Island    25417\n",
       "San Francisco-Oakland-Fremont               22710\n",
       "Name: city, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What five cities have the most measurements?\n",
    "us_cities.city.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf77b13",
   "metadata": {
    "papermill": {
     "duration": 0.019429,
     "end_time": "2021-11-09T00:04:02.559647",
     "exception": false,
     "start_time": "2021-11-09T00:04:02.540218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# More queries\n",
    "\n",
    "If you want multiple columns, you can select them with a comma between the names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48dc0eb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:04:02.605048Z",
     "iopub.status.busy": "2021-11-09T00:04:02.604040Z",
     "iopub.status.idle": "2021-11-09T00:04:02.607170Z",
     "shell.execute_reply": "2021-11-09T00:04:02.606619Z"
    },
    "papermill": {
     "duration": 0.027788,
     "end_time": "2021-11-09T00:04:02.607322",
     "exception": false,
     "start_time": "2021-11-09T00:04:02.579534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT city, country\n",
    "        FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "        WHERE country = 'US'\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4059ed20",
   "metadata": {
    "papermill": {
     "duration": 0.020898,
     "end_time": "2021-11-09T00:04:02.648955",
     "exception": false,
     "start_time": "2021-11-09T00:04:02.628057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can select all columns with a `*` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "459dee1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:04:02.694901Z",
     "iopub.status.busy": "2021-11-09T00:04:02.693966Z",
     "iopub.status.idle": "2021-11-09T00:04:02.696850Z",
     "shell.execute_reply": "2021-11-09T00:04:02.696196Z"
    },
    "papermill": {
     "duration": 0.027801,
     "end_time": "2021-11-09T00:04:02.696987",
     "exception": false,
     "start_time": "2021-11-09T00:04:02.669186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "        WHERE country = 'US'\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4459e8",
   "metadata": {
    "papermill": {
     "duration": 0.019716,
     "end_time": "2021-11-09T00:04:02.736838",
     "exception": false,
     "start_time": "2021-11-09T00:04:02.717122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Q&A: Notes on formatting\n",
    "\n",
    "The formatting of the SQL query might feel unfamiliar. If you have any questions, you can ask in the comments section at the bottom of this page.  Here are answers to two common questions:\n",
    "\n",
    "### **Question: What's up with the triple quotation marks (\"\"\")?**\n",
    "\n",
    "_Answer_: These tell Python that everything inside them is a single string, even though we have line breaks in it. The line breaks aren't necessary, but they make it easier to read your query.\n",
    "\n",
    "### **Question: Do you need to capitalize SELECT and FROM?**\n",
    "\n",
    "_Answer_: No, SQL doesn't care about capitalization. However, it's customary to capitalize your SQL commands, and it makes your queries a bit easier to read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7bd551",
   "metadata": {
    "papermill": {
     "duration": 0.019765,
     "end_time": "2021-11-09T00:04:02.776780",
     "exception": false,
     "start_time": "2021-11-09T00:04:02.757015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Working with big datasets\n",
    "\n",
    "BigQuery datasets can be huge. We allow you to do a lot of computation for free, but everyone has some limit.\n",
    "\n",
    "**Each Kaggle user can scan 5TB every 30 days for free. Once you hit that limit, you'll have to wait for it to reset.**\n",
    "\n",
    "The [biggest dataset currently on Kaggle](https://www.kaggle.com/github/github-repos) is 3TB, so you can go through your 30-day limit in a couple queries if you aren't careful.\n",
    "\n",
    "Don't worry though: we'll teach you how to avoid scanning too much data at once, so that you don't run over your limit.\n",
    "\n",
    "To begin,you can estimate the size of any query before running it. Here is an example using the (*very large!*) Hacker News dataset. To see how much data a query will scan, we create a `QueryJobConfig` object and set the `dry_run` parameter to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f2e60f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:04:02.824604Z",
     "iopub.status.busy": "2021-11-09T00:04:02.823854Z",
     "iopub.status.idle": "2021-11-09T00:04:03.225408Z",
     "shell.execute_reply": "2021-11-09T00:04:03.224778Z"
    },
    "papermill": {
     "duration": 0.428625,
     "end_time": "2021-11-09T00:04:03.225557",
     "exception": false,
     "start_time": "2021-11-09T00:04:02.796932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This query will process 538307091 bytes.\n"
     ]
    }
   ],
   "source": [
    "# Query to get the score column from every row where the type column has value \"job\"\n",
    "query = \"\"\"\n",
    "        SELECT score, title\n",
    "        FROM `bigquery-public-data.hacker_news.full`\n",
    "        WHERE type = \"job\" \n",
    "        \"\"\"\n",
    "\n",
    "# Create a QueryJobConfig object to estimate size of query without running it\n",
    "dry_run_config = bigquery.QueryJobConfig(dry_run=True)\n",
    "\n",
    "# API request - dry run query to estimate costs\n",
    "dry_run_query_job = client.query(query, job_config=dry_run_config)\n",
    "\n",
    "print(\"This query will process {} bytes.\".format(dry_run_query_job.total_bytes_processed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8516e6",
   "metadata": {
    "papermill": {
     "duration": 0.020562,
     "end_time": "2021-11-09T00:04:03.266975",
     "exception": false,
     "start_time": "2021-11-09T00:04:03.246413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can also specify a parameter when running the query to limit how much data you are willing to scan. Here's an example with a low limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18120feb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:04:03.316620Z",
     "iopub.status.busy": "2021-11-09T00:04:03.315961Z",
     "iopub.status.idle": "2021-11-09T00:04:03.875067Z",
     "shell.execute_reply": "2021-11-09T00:04:03.874481Z"
    },
    "papermill": {
     "duration": 0.587337,
     "end_time": "2021-11-09T00:04:03.875228",
     "exception": false,
     "start_time": "2021-11-09T00:04:03.287891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "500 Query exceeded limit for bytes billed: 1000000. 538968064 or higher required.\n\nLocation: US\nJob ID: 7bf91582-ce0e-4272-82d2-fb6e20be1147\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/saja/workspace/kaggle-learn/Intro to SQL/2-select-from-where.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saja/workspace/kaggle-learn/Intro%20to%20SQL/2-select-from-where.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m safe_query_job \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mquery(query, job_config\u001b[39m=\u001b[39msafe_config)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/saja/workspace/kaggle-learn/Intro%20to%20SQL/2-select-from-where.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# API request - try to run the query, and return a pandas DataFrame\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/saja/workspace/kaggle-learn/Intro%20to%20SQL/2-select-from-where.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m safe_query_job\u001b[39m.\u001b[39;49mto_dataframe()\n",
      "File \u001b[0;32m~/workspace/bin/anaconda3/envs/kaggle/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1683\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object)\u001b[0m\n\u001b[1;32m   1608\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_dataframe\u001b[39m(\n\u001b[1;32m   1609\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1610\u001b[0m     bqstorage_client: Optional[\u001b[39m\"\u001b[39m\u001b[39mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     geography_as_object: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1616\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpandas.DataFrame\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1617\u001b[0m     \u001b[39m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1618\u001b[0m \n\u001b[1;32m   1619\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1681\u001b[0m \u001b[39m            :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   1682\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1683\u001b[0m     query_result \u001b[39m=\u001b[39m wait_for_query(\u001b[39mself\u001b[39;49m, progress_bar_type, max_results\u001b[39m=\u001b[39;49mmax_results)\n\u001b[1;32m   1684\u001b[0m     \u001b[39mreturn\u001b[39;00m query_result\u001b[39m.\u001b[39mto_dataframe(\n\u001b[1;32m   1685\u001b[0m         bqstorage_client\u001b[39m=\u001b[39mbqstorage_client,\n\u001b[1;32m   1686\u001b[0m         dtypes\u001b[39m=\u001b[39mdtypes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1689\u001b[0m         geography_as_object\u001b[39m=\u001b[39mgeography_as_object,\n\u001b[1;32m   1690\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/bin/anaconda3/envs/kaggle/lib/python3.10/site-packages/google/cloud/bigquery/_tqdm_helpers.py:88\u001b[0m, in \u001b[0;36mwait_for_query\u001b[0;34m(query_job, progress_bar_type, max_results)\u001b[0m\n\u001b[1;32m     84\u001b[0m progress_bar \u001b[39m=\u001b[39m get_progress_bar(\n\u001b[1;32m     85\u001b[0m     progress_bar_type, \u001b[39m\"\u001b[39m\u001b[39mQuery is running\u001b[39m\u001b[39m\"\u001b[39m, default_total, \u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m progress_bar \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m query_job\u001b[39m.\u001b[39;49mresult(max_results\u001b[39m=\u001b[39;49mmax_results)\n\u001b[1;32m     90\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/workspace/bin/anaconda3/envs/kaggle/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1499\u001b[0m, in \u001b[0;36mQueryJob.result\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[39mif\u001b[39;00m retry_do_query \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m job_retry \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1497\u001b[0m         do_get_result \u001b[39m=\u001b[39m job_retry(do_get_result)\n\u001b[0;32m-> 1499\u001b[0m     do_get_result()\n\u001b[1;32m   1501\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mGoogleAPICallError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m   1502\u001b[0m     exc\u001b[39m.\u001b[39mmessage \u001b[39m=\u001b[39m _EXCEPTION_FOOTER_TEMPLATE\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1503\u001b[0m         message\u001b[39m=\u001b[39mexc\u001b[39m.\u001b[39mmessage, location\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocation, job_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjob_id\n\u001b[1;32m   1504\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/bin/anaconda3/envs/kaggle/lib/python3.10/site-packages/google/api_core/retry.py:283\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m target \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    280\u001b[0m sleep_generator \u001b[39m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    281\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maximum, multiplier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiplier\n\u001b[1;32m    282\u001b[0m )\n\u001b[0;32m--> 283\u001b[0m \u001b[39mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    284\u001b[0m     target,\n\u001b[1;32m    285\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predicate,\n\u001b[1;32m    286\u001b[0m     sleep_generator,\n\u001b[1;32m    287\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_deadline,\n\u001b[1;32m    288\u001b[0m     on_error\u001b[39m=\u001b[39;49mon_error,\n\u001b[1;32m    289\u001b[0m )\n",
      "File \u001b[0;32m~/workspace/bin/anaconda3/envs/kaggle/lib/python3.10/site-packages/google/api_core/retry.py:190\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39mfor\u001b[39;00m sleep \u001b[39min\u001b[39;00m sleep_generator:\n\u001b[1;32m    189\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[39mreturn\u001b[39;00m target()\n\u001b[1;32m    192\u001b[0m     \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[39m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/workspace/bin/anaconda3/envs/kaggle/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1489\u001b[0m, in \u001b[0;36mQueryJob.result.<locals>.do_get_result\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retry_do_query \u001b[39m=\u001b[39m retry_do_query\n\u001b[1;32m   1487\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_job_retry \u001b[39m=\u001b[39m job_retry\n\u001b[0;32m-> 1489\u001b[0m \u001b[39msuper\u001b[39;49m(QueryJob, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mresult(retry\u001b[39m=\u001b[39;49mretry, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1491\u001b[0m \u001b[39m# Since the job could already be \"done\" (e.g. got a finished job\u001b[39;00m\n\u001b[1;32m   1492\u001b[0m \u001b[39m# via client.get_job), the superclass call to done() might not\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m \u001b[39m# set the self._query_results cache.\u001b[39;00m\n\u001b[1;32m   1494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reload_query_results(retry\u001b[39m=\u001b[39mretry, timeout\u001b[39m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/workspace/bin/anaconda3/envs/kaggle/lib/python3.10/site-packages/google/cloud/bigquery/job/base.py:728\u001b[0m, in \u001b[0;36m_AsyncJob.result\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_begin(retry\u001b[39m=\u001b[39mretry, timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    727\u001b[0m kwargs \u001b[39m=\u001b[39m {} \u001b[39mif\u001b[39;00m retry \u001b[39mis\u001b[39;00m DEFAULT_RETRY \u001b[39melse\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mretry\u001b[39m\u001b[39m\"\u001b[39m: retry}\n\u001b[0;32m--> 728\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(_AsyncJob, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/workspace/bin/anaconda3/envs/kaggle/lib/python3.10/site-packages/google/api_core/future/polling.py:137\u001b[0m, in \u001b[0;36mPollingFuture.result\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking_poll(timeout\u001b[39m=\u001b[39mtimeout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[39m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[39m# Pylint doesn't recognize that this is valid in this case.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    139\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "\u001b[0;31mInternalServerError\u001b[0m: 500 Query exceeded limit for bytes billed: 1000000. 538968064 or higher required.\n\nLocation: US\nJob ID: 7bf91582-ce0e-4272-82d2-fb6e20be1147\n"
     ]
    }
   ],
   "source": [
    "# Only run the query if it's less than 1 MB\n",
    "ONE_MB = 1000*1000\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_MB)\n",
    "\n",
    "# Set up the query (will only run if it's less than 1 MB)\n",
    "safe_query_job = client.query(query, job_config=safe_config)\n",
    "\n",
    "# API request - try to run the query, and return a pandas DataFrame\n",
    "safe_query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ea5c7f",
   "metadata": {
    "papermill": {
     "duration": 0.020991,
     "end_time": "2021-11-09T00:04:03.918017",
     "exception": false,
     "start_time": "2021-11-09T00:04:03.897026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this case, the query was cancelled, because the limit of 1 MB was exceeded.  However, we can increase the limit to run the query successfully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12384567",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T00:04:03.964660Z",
     "iopub.status.busy": "2021-11-09T00:04:03.963935Z",
     "iopub.status.idle": "2021-11-09T00:04:07.751971Z",
     "shell.execute_reply": "2021-11-09T00:04:07.751302Z"
    },
    "papermill": {
     "duration": 3.812686,
     "end_time": "2021-11-09T00:04:07.752131",
     "exception": false,
     "start_time": "2021-11-09T00:04:03.939445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.73764486479286"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only run the query if it's less than 1 GB\n",
    "ONE_GB = 1000*1000*1000\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_GB)\n",
    "\n",
    "# Set up the query (will only run if it's less than 1 GB)\n",
    "safe_query_job = client.query(query, job_config=safe_config)\n",
    "\n",
    "# API request - try to run the query, and return a pandas DataFrame\n",
    "job_post_scores = safe_query_job.to_dataframe()\n",
    "\n",
    "# Print average score for job posts\n",
    "job_post_scores.score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eb8f22",
   "metadata": {
    "papermill": {
     "duration": 0.021518,
     "end_time": "2021-11-09T00:04:07.796888",
     "exception": false,
     "start_time": "2021-11-09T00:04:07.775370",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Your turn\n",
    "\n",
    "Writing **SELECT** statements is the key to using SQL. So **[try your new skills](./2-exercise-select-from-where.ipynb)**!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26ccd6d",
   "metadata": {
    "papermill": {
     "duration": 0.021319,
     "end_time": "2021-11-09T00:04:07.839993",
     "exception": false,
     "start_time": "2021-11-09T00:04:07.818674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-sql/discussion) to chat with other learners.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('kaggle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.429016,
   "end_time": "2021-11-09T00:04:08.471595",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-09T00:03:50.042579",
   "version": "2.3.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4ed1ec8855a62064c619c0d2fa574b8b147199d51dd235074c0ce2edf822ef7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
